

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>gp.gp &mdash; gaussian_processes 1.0.0 documentation</title>
    
    <link rel="stylesheet" href="../../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '1.0.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="gaussian_processes 1.0.0 documentation" href="../../index.html" />
    <link rel="up" title="Module code" href="../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../../np-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">gaussian_processes 1.0.0 documentation</a> &raquo;</li>
          <li><a href="../index.html" accesskey="U">Module code</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <h1>Source code for gp.gp</h1><div class="highlight"><pre>
<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;GP&quot;</span><span class="p">]</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">scipy.optimize</span> <span class="kn">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">from</span> <span class="nn">.ext</span> <span class="kn">import</span> <span class="n">gp_c</span>

<span class="n">DTYPE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span>
<span class="n">EPS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">DTYPE</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
<span class="n">MIN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp2</span><span class="p">(</span><span class="n">DTYPE</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">DTYPE</span><span class="p">)</span><span class="o">.</span><span class="n">minexp</span> <span class="o">+</span> <span class="mi">4</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">memoprop</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Memoized property.</span>

<span class="sd">    When the property is accessed for the first time, the return value</span>
<span class="sd">    is stored and that value is given on subsequent calls. The memoized</span>
<span class="sd">    value can be cleared by calling &#39;del prop&#39;, where prop is the name</span>
<span class="sd">    of the property.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fname</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span>

    <span class="k">def</span> <span class="nf">fget</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">fname</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memoized</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_memoized</span><span class="p">[</span><span class="n">fname</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memoized</span><span class="p">[</span><span class="n">fname</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">fdel</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memoized</span><span class="p">[</span><span class="n">fname</span><span class="p">]</span>

    <span class="n">prop</span> <span class="o">=</span> <span class="nb">property</span><span class="p">(</span><span class="n">fget</span><span class="o">=</span><span class="n">fget</span><span class="p">,</span> <span class="n">fdel</span><span class="o">=</span><span class="n">fdel</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="n">f</span><span class="o">.</span><span class="n">__doc__</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">prop</span>


<div class="viewcode-block" id="GP"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP">[docs]</a><span class="k">class</span> <span class="nc">GP</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">    Gaussian Process object.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    K : :class:`~gp.kernels.base.Kernel`</span>
<span class="sd">        Kernel object</span>
<span class="sd">    x : numpy.ndarray</span>
<span class="sd">        :math:`n` array of input locations</span>
<span class="sd">    y : numpy.ndarray</span>
<span class="sd">        :math:`n` array of input observations</span>
<span class="sd">    s : number (default=0)</span>
<span class="sd">        Standard deviation of observation noise</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Initialize the GP.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_memoized</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_x</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_y</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_s</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c">#: Kernel for the gaussian process, of type</span>
        <span class="c">#: :class:`~gp.kernels.base.Kernel`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">K</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">s</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">x</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Vector of input locations.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        x : numpy.ndarray</span>
<span class="sd">            :math:`n` array, where :math:`n` is the number of</span>
<span class="sd">            locations.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x</span>

    <span class="nd">@x.setter</span>
<div class="viewcode-block" id="GP.x"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.x">[docs]</a>    <span class="k">def</span> <span class="nf">x</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">val</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_memoized</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_x</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">DTYPE</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span>
</div>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">y</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Vector of input observations.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y : numpy.ndarray</span>
<span class="sd">            :math:`n` array, where :math:`n` is the number of</span>
<span class="sd">            observations.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span>

    <span class="nd">@y.setter</span>
<div class="viewcode-block" id="GP.y"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.y">[docs]</a>    <span class="k">def</span> <span class="nf">y</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">val</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_memoized</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_y</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">DTYPE</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s">&quot;invalid shape for y: </span><span class="si">%s</span><span class="s">&quot;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</div>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">s</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Standard deviation of the observation noise for the gaussian</span>
<span class="sd">        process.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        s : numpy.float64</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_s</span>

    <span class="nd">@s.setter</span>
<div class="viewcode-block" id="GP.s"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.s">[docs]</a>    <span class="k">def</span> <span class="nf">s</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">val</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_s</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_memoized</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_s</span> <span class="o">=</span> <span class="n">DTYPE</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
</div>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Gaussian process parameters.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : numpy.ndarray</span>
<span class="sd">           Consists of the kernel&#39;s parameters, `self.K.params`, and the</span>
<span class="sd">           observation noise parameter, :math:`s`, in that order.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="o">.</span><span class="n">params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_s</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params</span>

    <span class="nd">@params.setter</span>
<div class="viewcode-block" id="GP.params"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.params">[docs]</a>    <span class="k">def</span> <span class="nf">params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">!=</span> <span class="n">val</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_memoized</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">val</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">val</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</div>
<div class="viewcode-block" id="GP.copy"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.copy">[docs]</a>    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a copy of the gaussian process object.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        gp : :class:`~gp.gp.GP`</span>
<span class="sd">            New gaussian process object</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_gp</span> <span class="o">=</span> <span class="n">GP</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">)</span>
        <span class="n">new_gp</span><span class="o">.</span><span class="n">_memoized</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_memoized</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_gp</span>
</div>
    <span class="nd">@memoprop</span>
<div class="viewcode-block" id="GP.Kxx"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.Kxx">[docs]</a>    <span class="k">def</span> <span class="nf">Kxx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Kernel covariance matrix :math:`\mathbf{K}_{xx}`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Kxx : numpy.ndarray</span>
<span class="sd">            :math:`n\times n` covariance matrix</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The entry at index :math:`(i, j)` is defined as:</span>

<span class="sd">        .. math:: K_{x_ix_j} = K(x_i, x_j) + s^2\delta(x_i-x_j),</span>

<span class="sd">        where :math:`K(\cdot{})` is the kernel function, :math:`s` is the</span>
<span class="sd">        standard deviation of the observation noise, and :math:`\delta`</span>
<span class="sd">        is the Dirac delta function.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_s</span>
        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">K</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DTYPE</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">s</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">K</span>
</div>
    <span class="nd">@memoprop</span>
<div class="viewcode-block" id="GP.Kxx_J"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.Kxx_J">[docs]</a>    <span class="k">def</span> <span class="nf">Kxx_J</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="o">.</span><span class="n">jacobian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</div>
    <span class="nd">@memoprop</span>
<div class="viewcode-block" id="GP.Kxx_H"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.Kxx_H">[docs]</a>    <span class="k">def</span> <span class="nf">Kxx_H</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</div>
    <span class="nd">@memoprop</span>
<div class="viewcode-block" id="GP.Lxx"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.Lxx">[docs]</a>    <span class="k">def</span> <span class="nf">Lxx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Cholesky decomposition of the kernel covariance matrix.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Lxx : numpy.ndarray</span>
<span class="sd">            :math:`n\times n` lower triangular matrix</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The value is :math:`\mathbf{L}_{xx}`, such that</span>
<span class="sd">        :math:`\mathbf{K}_{xx} = \mathbf{L}_{xx}\mathbf{L}_{xx}^\top`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Kxx</span><span class="p">)</span>
</div>
    <span class="nd">@memoprop</span>
<div class="viewcode-block" id="GP.inv_Lxx"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.inv_Lxx">[docs]</a>    <span class="k">def</span> <span class="nf">inv_Lxx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Inverse cholesky decomposition of the kernel covariance matrix.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        inv_Lxx : numpy.ndarray</span>
<span class="sd">            :math:`n\times n` matrix</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The value is :math:`\mathbf{L}_{xx}^{-1}`, such that:</span>

<span class="sd">        .. math:: \mathbf{K}_{xx} = \mathbf{L}_{xx}\mathbf{L}_{xx}^\top</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Lxx</span><span class="p">)</span>
</div>
    <span class="nd">@memoprop</span>
<div class="viewcode-block" id="GP.inv_Kxx"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.inv_Kxx">[docs]</a>    <span class="k">def</span> <span class="nf">inv_Kxx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Inverse kernel covariance matrix, :math:`\mathbf{K}_{xx}^{-1}`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        inv_Kxx : numpy.ndarray</span>
<span class="sd">            :math:`n\times n` matrix</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Li</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_Lxx</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Li</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Li</span><span class="p">)</span>
</div>
    <span class="nd">@memoprop</span>
<div class="viewcode-block" id="GP.inv_Kxx_y"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.inv_Kxx_y">[docs]</a>    <span class="k">def</span> <span class="nf">inv_Kxx_y</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Dot product of the inverse kernel covariance matrix and of</span>
<span class="sd">        observation vector.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        inv_Kxx_y : numpy.ndarray</span>
<span class="sd">            :math:`n` array</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This is defined as :math:`\mathbf{K}_{xx}^{-1}\mathbf{y}`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inv_Kxx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span><span class="p">)</span>
</div>
    <span class="nd">@memoprop</span>
<div class="viewcode-block" id="GP.log_lh"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.log_lh">[docs]</a>    <span class="k">def</span> <span class="nf">log_lh</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Marginal log likelihood.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        log_lh : numpy.float64</span>
<span class="sd">            Marginal log likelihood</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This is the log likelihood of observations :math:`\mathbf{y}`</span>
<span class="sd">        given locations :math:`\mathbf{x}` and kernel parameters</span>
<span class="sd">        :math:`\theta`. It is defined by Eq. 5.8 of [RW06]_:</span>

<span class="sd">        .. math::</span>

<span class="sd">            \log{p(\mathbf{y} | \mathbf{x}, \mathbf{\theta})} = -\frac{1}{2}\mathbf{y}^\top \mathbf{K}_{xx}^{-1}\mathbf{y} - \frac{1}{2}\log{\left|\mathbf{K}_{xx}\right|}-\frac{d}{2}\log{2\pi},</span>

<span class="sd">        where :math:`d` is the dimensionality of :math:`\mathbf{x}`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span>
        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kxx</span>
        <span class="n">Kiy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_Kxx_y</span>
        <span class="k">return</span> <span class="n">DTYPE</span><span class="p">(</span><span class="n">gp_c</span><span class="o">.</span><span class="n">log_lh</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">Kiy</span><span class="p">))</span>
</div>
    <span class="nd">@memoprop</span>
<div class="viewcode-block" id="GP.lh"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.lh">[docs]</a>    <span class="k">def</span> <span class="nf">lh</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Marginal likelihood.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        lh : numpy.float64</span>
<span class="sd">            Marginal likelihood</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This is the likelihood of observations :math:`\mathbf{y}` given</span>
<span class="sd">        locations :math:`\mathbf{x}` and kernel parameters</span>
<span class="sd">        :math:`\theta`. It is defined as:</span>

<span class="sd">        .. math::</span>

<span class="sd">            p(\mathbf{y} | \mathbf{x}, \mathbf{\theta}) = \left(2\pi\right)^{-\frac{d}{2}}\left|\mathbf{K}_{xx}\right|^{-\frac{1}{2}}\exp\left(-\frac{1}{2}\mathbf{y}^\top\mathbf{K}_{xx}^{-1}\mathbf{y}\right)</span>

<span class="sd">        where :math:`d` is the dimensionality of :math:`\mathbf{x}`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">llh</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_lh</span>
        <span class="k">if</span> <span class="n">llh</span> <span class="o">&lt;</span> <span class="n">MIN</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_lh</span><span class="p">)</span>
</div>
    <span class="nd">@memoprop</span>
<div class="viewcode-block" id="GP.dloglh_dtheta"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.dloglh_dtheta">[docs]</a>    <span class="k">def</span> <span class="nf">dloglh_dtheta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Derivative of the marginal log likelihood.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dloglh_dtheta : numpy.ndarray</span>
<span class="sd">            :math:`n_\theta`-length vector of derivatives, where</span>
<span class="sd">            :math:`n_\theta` is the number of parameters (equivalent to</span>
<span class="sd">            ``len(self.params)``).</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This is a vector of first partial derivatives of the log</span>
<span class="sd">        likelihood with respect to its parameters :math:`\theta`. It is</span>
<span class="sd">        defined by Equation 5.9 of [RW06]_:</span>

<span class="sd">        .. math::</span>

<span class="sd">            \frac{\partial}{\partial\theta_i}\log{p(\mathbf{y}|\mathbf{x},\theta)}=\frac{1}{2}\mathbf{y}^\top\mathbf{K}_{xx}^{-1}\frac{\partial\mathbf{K}_{xx}}{\partial\theta_i}\mathbf{K}_{xx}^{-1}\mathbf{y}-\frac{1}{2}\mathbf{tr}\left(\mathbf{K}_{xx}^{-1}\frac{\partial\mathbf{K}_{xx}}{\partial\theta_i}\right)</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span>
        <span class="n">dloglh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">))</span>
        <span class="n">Ki</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_Kxx</span>
        <span class="n">Kj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kxx_J</span>
        <span class="n">Kiy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_Kxx_y</span>
        <span class="n">gp_c</span><span class="o">.</span><span class="n">dloglh_dtheta</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">Ki</span><span class="p">,</span> <span class="n">Kj</span><span class="p">,</span> <span class="n">Kiy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_s</span><span class="p">,</span> <span class="n">dloglh</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dloglh</span>
</div>
    <span class="nd">@memoprop</span>
<div class="viewcode-block" id="GP.dlh_dtheta"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.dlh_dtheta">[docs]</a>    <span class="k">def</span> <span class="nf">dlh_dtheta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Derivative of the marginal likelihood.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dlh_dtheta : numpy.ndarray</span>
<span class="sd">            :math:`n_\theta`-length vector of derivatives, where</span>
<span class="sd">            :math:`n_\theta` is the number of parameters (equivalent to</span>
<span class="sd">            ``len(self.params)``).</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This is a vector of first partial derivatives of the likelihood</span>
<span class="sd">        with respect to its parameters :math:`\theta`.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span>
        <span class="n">dlh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">))</span>
        <span class="n">Ki</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_Kxx</span>
        <span class="n">Kj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kxx_J</span>
        <span class="n">Kiy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_Kxx_y</span>
        <span class="n">lh</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lh</span>
        <span class="n">gp_c</span><span class="o">.</span><span class="n">dlh_dtheta</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">Ki</span><span class="p">,</span> <span class="n">Kj</span><span class="p">,</span> <span class="n">Kiy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_s</span><span class="p">,</span> <span class="n">lh</span><span class="p">,</span> <span class="n">dlh</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dlh</span>
</div>
    <span class="nd">@memoprop</span>
<div class="viewcode-block" id="GP.d2lh_dtheta2"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.d2lh_dtheta2">[docs]</a>    <span class="k">def</span> <span class="nf">d2lh_dtheta2</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Second derivative of the marginal likelihood.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        d2lh_dtheta2 : numpy.ndarray</span>
<span class="sd">            :math:`n_\theta`-length vector of derivatives, where</span>
<span class="sd">            :math:`n_\theta` is the number of parameters (equivalent to</span>
<span class="sd">            ``len(self.params)``).</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This is a matrix of second partial derivatives of the likelihood</span>
<span class="sd">        with respect to its parameters :math:`\theta`.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span>
        <span class="n">Ki</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_Kxx</span>
        <span class="n">Kj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kxx_J</span>
        <span class="n">Kh</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kxx_H</span>
        <span class="n">Kiy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_Kxx_y</span>
        <span class="n">lh</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lh</span>
        <span class="n">dlh</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dlh_dtheta</span>
        <span class="n">d2lh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)))</span>
        <span class="n">gp_c</span><span class="o">.</span><span class="n">d2lh_dtheta2</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">Ki</span><span class="p">,</span> <span class="n">Kj</span><span class="p">,</span> <span class="n">Kh</span><span class="p">,</span> <span class="n">Kiy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_s</span><span class="p">,</span> <span class="n">lh</span><span class="p">,</span> <span class="n">dlh</span><span class="p">,</span> <span class="n">d2lh</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">d2lh</span>
</div>
<div class="viewcode-block" id="GP.Kxoxo"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.Kxoxo">[docs]</a>    <span class="k">def</span> <span class="nf">Kxoxo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xo</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Kernel covariance matrix of new sample locations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        xo : numpy.ndarray</span>
<span class="sd">            :math:`m` array of new sample locations</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Kxoxo : numpy.ndarray</span>
<span class="sd">            :math:`m\times m` covariance matrix</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This is defined as :math:`K(\mathbf{x^*}, \mathbf{x^*})`, where</span>
<span class="sd">        :math:`\mathbf{x^*}` are the new locations.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">(</span><span class="n">xo</span><span class="p">,</span> <span class="n">xo</span><span class="p">)</span>
</div>
<div class="viewcode-block" id="GP.Kxxo"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.Kxxo">[docs]</a>    <span class="k">def</span> <span class="nf">Kxxo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xo</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Kernel covariance matrix between given locations and new sample</span>
<span class="sd">        locations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        xo : numpy.ndarray</span>
<span class="sd">            :math:`m` array of new sample locations</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Kxxo : numpy.ndarray</span>
<span class="sd">            :math:`n\times m` covariance matrix</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This is defined as :math:`K(\mathbf{x},\mathbf{x^*})`, where</span>
<span class="sd">        :math:`\mathbf{x}` are the given locations and</span>
<span class="sd">        :math:`\mathbf{x^*}` are the new sample locations.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_x</span><span class="p">,</span> <span class="n">xo</span><span class="p">)</span>
</div>
<div class="viewcode-block" id="GP.Kxox"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.Kxox">[docs]</a>    <span class="k">def</span> <span class="nf">Kxox</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xo</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Kernel covariance matrix between new sample locations and given</span>
<span class="sd">        locations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        xo : numpy.ndarray</span>
<span class="sd">            :math:`m` array of new sample locations</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Kxox : numpy.ndarray</span>
<span class="sd">            :math:`m\times n` covariance matrix</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This is defined as :math:`K(\mathbf{x^*},\mathbf{x})`, where</span>
<span class="sd">        :math:`\mathbf{x^*}` are the new sample locations and</span>
<span class="sd">        :math:`\mathbf{x}` are the given locations</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">(</span><span class="n">xo</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x</span><span class="p">)</span>
</div>
<div class="viewcode-block" id="GP.mean"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.mean">[docs]</a>    <span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xo</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Predictive mean of the gaussian process.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        xo : numpy.ndarray</span>
<span class="sd">            :math:`m` array of new sample locations</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        mean : numpy.ndarray</span>
<span class="sd">            :math:`m` array of predictive means</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This is defined by Equation 2.23 of [RW06]_:</span>

<span class="sd">        .. math::</span>

<span class="sd">            \mathbf{m}(\mathbf{x^*})=K(\mathbf{x^*}, \mathbf{x})\mathbf{K}_{xx}^{-1}\mathbf{y}</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Kxox</span><span class="p">(</span><span class="n">xo</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_Kxx_y</span><span class="p">)</span>
</div>
<div class="viewcode-block" id="GP.cov"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.cov">[docs]</a>    <span class="k">def</span> <span class="nf">cov</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xo</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Predictive covariance of the gaussian process.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        xo : numpy.ndarray</span>
<span class="sd">            :math:`m` array of new sample locations</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        cov : numpy.ndarray</span>
<span class="sd">            :math:`m\times m` array of predictive covariances</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This is defined by Eq. 2.24 of [RW06]_:</span>

<span class="sd">        .. math::</span>

<span class="sd">            \mathbf{C}=K(\mathbf{x^*}, \mathbf{x^*}) - K(\mathbf{x^*}, \mathbf{x})\mathbf{K}_{xx}^{-1}K(\mathbf{x}, \mathbf{x^*})</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Kxoxo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kxoxo</span><span class="p">(</span><span class="n">xo</span><span class="p">)</span>
        <span class="n">Kxox</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kxox</span><span class="p">(</span><span class="n">xo</span><span class="p">)</span>
        <span class="n">Kxxo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kxxo</span><span class="p">(</span><span class="n">xo</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Kxoxo</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Kxox</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inv_Kxx</span><span class="p">,</span> <span class="n">Kxxo</span><span class="p">))</span>
</div>
<div class="viewcode-block" id="GP.dm_dtheta"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.dm_dtheta">[docs]</a>    <span class="k">def</span> <span class="nf">dm_dtheta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xo</span><span class="p">):</span>
        <span class="sd">r&quot;&quot;&quot;</span>
<span class="sd">        Derivative of the mean of the gaussian process with respect to</span>
<span class="sd">        its parameters, and evaluated at `xo`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        xo : numpy.ndarray</span>
<span class="sd">            :math:`m` array of new sample locations</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dm_dtheta : numpy.ndarray</span>
<span class="sd">            :math:`n_p\times m` array, where :math:`n_p` is the</span>
<span class="sd">            number of parameters (see `params`).</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The analytic form is:</span>

<span class="sd">        .. math::</span>

<span class="sd">            \frac{\partial}{\partial \theta_i}m(\mathbf{x^*})=\frac{\partial K(\mathbf{x^*}, \mathbf{x})}{\partial \theta_i}\mathbf{K}_{xx}^{-1}\mathbf{y} - K(\mathbf{x^*}, \mathbf{x})\mathbf{K}_{xx}^{-1}\frac{\partial \mathbf{K}_{xx}}{\partial \theta_i}\mathbf{K}_{xx}^{-1}\mathbf{y}</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span>
        <span class="n">Ki</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_Kxx</span>
        <span class="n">Kj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kxx_J</span>
        <span class="n">Kjxo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="o">.</span><span class="n">jacobian</span><span class="p">(</span><span class="n">xo</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x</span><span class="p">)</span>
        <span class="n">Kxox</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Kxox</span><span class="p">(</span><span class="n">xo</span><span class="p">)</span>

        <span class="n">dm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">),</span> <span class="n">xo</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>
        <span class="n">gp_c</span><span class="o">.</span><span class="n">dm_dtheta</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">Ki</span><span class="p">,</span> <span class="n">Kj</span><span class="p">,</span> <span class="n">Kjxo</span><span class="p">,</span> <span class="n">Kxox</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_s</span><span class="p">,</span> <span class="n">dm</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">dm</span>
</div>
<div class="viewcode-block" id="GP.plot"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.plot">[docs]</a>    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&#39;k&#39;</span><span class="p">,</span> <span class="n">markercolor</span><span class="o">=</span><span class="s">&#39;r&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot the predictive mean and variance of the gaussian process.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ax : `matplotlib.pyplot.axes.Axes` (optional)</span>
<span class="sd">            The axes on which to draw the graph. Defaults to</span>
<span class="sd">            ``plt.gca()`` if not given.</span>
<span class="sd">        xlim : (lower x limit, upper x limit) (optional)</span>
<span class="sd">            The limits of the x-axis. Defaults to the minimum and</span>
<span class="sd">            maximum of `x` if not given.</span>
<span class="sd">        color : str (optional)</span>
<span class="sd">            The line color to use. The default is &#39;k&#39; (black).</span>
<span class="sd">        markercolor : str (optional)</span>
<span class="sd">            The marker color to use. The default is &#39;r&#39; (red).</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span>

        <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">xlim</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">xlim</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xlim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xlim</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">cov</span><span class="p">))</span>
        <span class="n">upper</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">std</span>
        <span class="n">lower</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">-</span> <span class="n">std</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s">&#39;o&#39;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">markercolor</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">*</span><span class="n">xlim</span><span class="p">)</span>
</div>
<div class="viewcode-block" id="GP.fit_MLII"><a class="viewcode-back" href="../../gp.gp.html#gp.gp.GP.fit_MLII">[docs]</a>    <span class="k">def</span> <span class="nf">fit_MLII</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params_to_fit</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">randf</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">nrestart</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit parameters of the gaussian process using MLII (maximum</span>
<span class="sd">        likelihood) estimation.</span>

<span class="sd">        Note that this method modifies the gaussian process in</span>
<span class="sd">        place. After the method is run, the `GP` object will have new</span>
<span class="sd">        parameters set to the best ones found during the optimization.</span>

<span class="sd">        The optimization algorithm used is L-BFGS-B.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        params_to_fit : boolean array_like</span>
<span class="sd">            A list of booleans corresponding to the gaussian process</span>
<span class="sd">            parameters, indicating which parameters should be</span>
<span class="sd">            fit. Parameters which are not fit keep their current value.</span>

<span class="sd">        bounds : list of tuples (optional)</span>
<span class="sd">            The upper and lower bounds for each parameter that is being</span>
<span class="sd">            fit; use ``None`` to specify no bound. If not specified,</span>
<span class="sd">            the bounds default to ``(EPS, None)``, where</span>
<span class="sd">            ``EPS=numpy.finfo(float).eps``.</span>

<span class="sd">        randf : list of functions (optional)</span>
<span class="sd">            A list of functions to give an initial starting value for</span>
<span class="sd">            each parameter that is being fit. The functions should</span>
<span class="sd">            take no arguments, and return a numpy.float64. If not</span>
<span class="sd">            specified, the functions default to ``lambda:</span>
<span class="sd">            abs(numpy.random.normal())``.</span>

<span class="sd">        nrestart : int (optional)</span>
<span class="sd">            Number of random restarts to use. The best parameters out of</span>
<span class="sd">            all the random restarts are used.</span>

<span class="sd">        verbose : bool (optional)</span>
<span class="sd">            Whether to print information about the optimization.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c"># original parameter list</span>
        <span class="n">params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
        <span class="c"># boolean array of which parameters to fit</span>
        <span class="n">fitmask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">params_to_fit</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s">&#39;bool&#39;</span><span class="p">)</span>

        <span class="c"># default for bounds</span>
        <span class="k">if</span> <span class="n">bounds</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">bounds</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">((</span><span class="n">EPS</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params_to_fit</span> <span class="k">if</span> <span class="n">p</span><span class="p">)</span>
        <span class="c"># default for randf</span>
        <span class="k">if</span> <span class="n">randf</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">randf</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
                <span class="k">lambda</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">())</span>
                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params_to_fit</span> <span class="k">if</span> <span class="n">p</span><span class="p">)</span>

        <span class="c"># figure out the indices of the params we are fitting</span>
        <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">iparam</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">params_to_fit</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">iparam</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
                <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">iparam</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>

        <span class="c"># update the GP object with new parameter values</span>
        <span class="k">def</span> <span class="nf">new_params</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
            <span class="n">th</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
            <span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">j</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">th</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                   <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">iparam</span><span class="p">)]</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="c"># negative log likelihood</span>
        <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">new_params</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">log_lh</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="c"># jacobian of the negative log likelihood</span>
        <span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">new_params</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">dloglh_dtheta</span><span class="p">[</span><span class="n">fitmask</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="k">def</span> <span class="nf">cb</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
            <span class="k">print</span> <span class="n">theta</span>

        <span class="c"># run the optimization a few times to find the best fit</span>
        <span class="n">args</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nrestart</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">bounds</span><span class="p">)))</span>
        <span class="n">fval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">nrestart</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">nrestart</span><span class="p">):</span>
            <span class="n">p0</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">r</span><span class="p">()</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">randf</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">new_params</span><span class="p">(</span><span class="n">p0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;      p0 = </span><span class="si">%s</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">p0</span><span class="p">,)</span>
            <span class="n">popt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
                <span class="n">fun</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">p0</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&#39;L-BFGS-B&#39;</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">)</span>
            <span class="n">args</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">popt</span><span class="p">[</span><span class="s">&#39;x&#39;</span><span class="p">]</span>
            <span class="n">fval</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">popt</span><span class="p">[</span><span class="s">&#39;fun&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span> <span class="s">&quot;      -MLL(</span><span class="si">%s</span><span class="s">) = </span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">fval</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="c"># choose the parameters that give the best MLL</span>
        <span class="k">if</span> <span class="n">args</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">fval</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s">&quot;Could not find MLII parameter estimates&quot;</span><span class="p">)</span>

        <span class="c"># update our parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">new_params</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">fval</span><span class="p">)])</span></div></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../../np-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="../../index.html">gaussian_processes 1.0.0 documentation</a> &raquo;</li>
          <li><a href="../index.html" >Module code</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2013, Jessica B. Hamrick.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
  </body>
</html>